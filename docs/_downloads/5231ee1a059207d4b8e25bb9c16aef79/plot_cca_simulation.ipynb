{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Contrast-CCA on simulated MEG data\n\nThis example shows how to simulate MEG data with individual differences and then extract the associations with CCA.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import necessary libraries.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nimport warnings\nimport os\n\nimport mne\nimport numpy as np\n\nimport scipy.stats\nfrom scipy.linalg import cholesky\n\nimport matplotlib.pyplot as plt \nimport matplotlib as mpl\n\nfrom sparsecca import cca_ipls\nfrom sklearn.decomposition import PCA\n\n# Suppress warnings and set plotting and logging properties\nplt.rcParams.update({'font.size': 10.0})\nlogging.getLogger('mne').setLevel(logging.ERROR)\nmne.viz.set_3d_backend('pyvista')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set up paths.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_path = mne.datasets.sample.data_path()\nsubjects_dir = os.path.join(data_path, 'subjects')\nsubject = 'sample'\n\nraw_fname = os.path.join(data_path, 'MEG', subject, 'sample_audvis_raw.fif')\nfwd_fname = os.path.join(data_path, 'MEG', subject, 'sample_audvis-meg-oct-6-fwd.fif')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read raw, drop eeg data and resample.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw = mne.io.Raw(raw_fname, preload=True)\npicks = mne.pick_types(raw.info, meg=True)\nraw.drop_channels([ch_name for ch_idx, ch_name in enumerate(raw.info['ch_names']) \n                   if ch_idx not in picks])\nraw.resample(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define some variables needed later on.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "info = raw.info\nfwd = mne.read_forward_solution(fwd_fname)\nsrc = fwd['src']\n\nlength = 50\nsfreq = info['sfreq']\ntstep = 1/sfreq\nn_times = length / tstep\nevents = [[0, 0, 1]]\nfmin, fmax = 1, 20\ninv_method = 'dSPM'\njitter_factor = 0.01\nn_perm = 500\n\n# how many canonical correlations are computed\n# and to which dimension to reduce the contrast data\nn_cca_components = 1\nn_contrast_components = 4\n\n# penalties for CCA, use no penalty for now\npenalty_behav_ratio=1.0\npenalty_behav = 0.0\npenalty_contrast_ratio = 0.0\npenalty_contrast = 0.0\n\n# first condition is from beginning to middle,\n# while second is from middle to end\ncond_1_ival = 0, length / 2\ncond_2_ival = length / 2, length\n\n# For reproducibility, fix the random state\nrand_state = np.random.RandomState(23)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define function to get extended label spanning vertices around a label center.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_label(regexp, extent=5):\n    \"\"\" get label by regexp\n    \"\"\"\n    orig_label = mne.read_labels_from_annot(\n        subject, regexp=regexp, subjects_dir=subjects_dir)[0]\n    center = mne.label.select_sources(\n        subject, orig_label, location='center', extent=0,\n        subjects_dir=subjects_dir).vertices[0]\n    label = mne.label.select_sources(\n        subject, orig_label, location='center', extent=extent,\n        subjects_dir=subjects_dir)\n    return label, center"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the function to get labels for parietal, precentral and temporal areas in both hemis.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "label_rh_par, center_rh_par = get_label('superiorparietal-rh')\nlabel_lh_par, center_lh_par = get_label('superiorparietal-lh')\nlabel_rh_prec, center_rh_prec = get_label('precentral-rh')\nlabel_lh_prec, center_lh_prec = get_label('precentral-lh')\nlabel_rh_temp, center_rh_temp = get_label('superiortemporal-rh')\nlabel_lh_temp, center_lh_temp = get_label('superiortemporal-lh')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define function to simulate raw data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def simulate(n_subjects, cond_1_deps, cond_2_deps):\n    \"\"\" Generates raw data with alpha oscillations from two resting-state like conditions \n    around cortex modulated by behavioral variables\n    \"\"\"\n\n    # make diagonal noise covariance and use it and fwd to make inverse operator\n    cov = mne.make_ad_hoc_cov(info)\n    inv = mne.minimum_norm.make_inverse_operator(info, fwd, cov)\n\n    raws = []\n    for subject_idx in range(n_subjects):\n\n        source_simulator = mne.simulation.SourceSimulator(src, tstep=tstep)\n\n        # let every subject have some subject-specific base activity\n        base_amp = 100e-10 * np.exp(rand_state.randn()/10)\n\n        # define helper functions to create alpha oscillations\n\n        def alpha_wave(base_freq, length, phase):\n            \"\"\" creates alpha wave with frequency and phase jitter \"\"\"\n            jitter_factor = 0.05\n            return np.sin(2.0 * np.pi * \n                (base_freq * np.arange(length) * tstep +\n                 np.cumsum(jitter_factor * rand_state.randn(int(length)))) + phase)\n\n        def get_modulator():\n            \"\"\" creates a boxcar-like random carrier wave \"\"\"\n            modulator = (np.array_split(np.ones(int(n_times / 2)), int(n_times/20)) + \n                         np.array_split(np.zeros(int(n_times / 2)), int(n_times/20)))\n            rand_state.shuffle(modulator)\n            modulator = np.concatenate(modulator, axis=0)\n            return modulator\n\n        # Add some base alpha activity to superior temporal areas, where both conditions\n        # behave similarly\n        source_signal = np.ones(int(n_times)) * alpha_wave(10, n_times, 0) * base_amp\n        source_simulator.add_data(label_lh_temp, source_signal*get_modulator(), events)\n        source_simulator.add_data(label_rh_temp, source_signal*get_modulator(), events)\n\n        # Add activity that depends on the behav variables\n        cond_1_factor = np.prod(np.exp(cond_1_deps[subject_idx]))\n        cond_2_factor = np.prod(np.exp(cond_2_deps[subject_idx]))\n        modulator = get_modulator()\n        cond_1_signal = np.concatenate([np.ones(int(n_times/2)), np.zeros(int(n_times/2))])\n        cond_1_signal = cond_1_signal * alpha_wave(10, n_times, 0) * base_amp * cond_1_factor\n        cond_2_signal = np.concatenate([np.zeros(int(n_times/2)), np.ones(int(n_times/2))])\n        cond_2_signal = cond_2_signal * alpha_wave(10, n_times, 0) * base_amp * cond_2_factor\n        source_signal = cond_1_signal + cond_2_signal\n        source_simulator.add_data(label_lh_par, source_signal*modulator, events)\n        source_simulator.add_data(label_rh_par, source_signal*modulator, events)\n\n        # Add activity that is independent of the behavioral variables but which differs\n        # between the first and second condition.\n        cond_1_factor, cond_2_factor = 2, 0.5\n        modulator = get_modulator()\n        cond_1_signal = np.concatenate([np.ones(int(n_times/2)), np.zeros(int(n_times/2))])\n        cond_1_signal = cond_1_signal * alpha_wave(10, n_times, 0) * base_amp * cond_1_factor\n        cond_2_signal = np.concatenate([np.zeros(int(n_times/2)), np.ones(int(n_times/2))])\n        cond_2_signal = cond_2_signal * alpha_wave(10, n_times, 0) * base_amp * cond_2_factor\n        source_signal = cond_1_signal + cond_2_signal\n        source_simulator.add_data(label_lh_prec, source_signal*modulator, events)\n        source_simulator.add_data(label_rh_prec, source_signal*modulator, events)\n\n        # Simulate these sources to create raw object\n        raw = mne.simulation.simulate_raw(info, source_simulator, forward=fwd)\n\n        # Add some 1/f noise to sensors with spatial structure induced by cov.\n        mne.simulation.add_noise(raw, cov, iir_filter=[0.2, -0.2, 0.04], random_state=rand_state)\n\n        raws.append(raw)\n\n    return raws, behav_data, inv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that there is a simulation function, simulate data.\nThe simulation sets up three areas of activation (temporal, parietal and precentral),\nand two different conditions (0s to 25s, and 25s to 50s).\nIn to temporal areas, we put an oscillatory dipole of 10Hz that oscillates \non some base amplitude, which varies subject by subject, and does not depend on the condition. \nTo precentral areas we put oscillatory dipole of 10Hz, that has amplitude of 2 * base amplitude\nin the first condition and 0.5 * base amplitude in the second condition, giving a \"constant\" \ndifference between the conditions.\nTo parietal areas we put oscillatory dipole of 10Hz, which can be set to vary with respect to\nbehavioral variables. Here we make it so that the first condition does not vary with the \nbehavioral variables, but the second condition is very correlated with the first\nbehavioral variable.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_subjects = 10\n\n# Generate behav data from multivariate normal distribution\nbehav_mean = [0, 0]\nbehav_cov = [[1, 0],\n             [0, 1]]\nbehav_data = []\nfor idx in range(n_subjects):\n    behav_data.append(rand_state.multivariate_normal(behav_mean, behav_cov))\nbehav_data = np.array(behav_data)\n\n# Make second condition positively correlated with the first behav variable\ncond_1_deps = np.zeros((n_subjects, 2))\ncond_2_deps = np.array([behav_data[:, 0], np.zeros(n_subjects)]).T\n\nraws, behavs, inv = simulate(n_subjects, cond_1_deps, cond_2_deps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take a look at the first raw.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raws[0].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot how the simulated data looks as a PSD averaged over channels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, (ax_1, ax_2) = plt.subplots(2)\nax_1.set_title('Cond 1')\nax_2.set_title('Cond 2')\nfig.suptitle('PSDs in sensor space')\nfor raw in raws:\n    psds, freqs = mne.time_frequency.psd_welch(\n        raw, fmin=fmin, fmax=fmax, n_fft=int(sfreq),\n        tmin=cond_1_ival[0], tmax=cond_1_ival[1])\n    ax_1.plot(freqs, np.mean(psds, axis=0))\n\n    psds, freqs = mne.time_frequency.psd_welch(\n        raw, fmin=fmin, fmax=fmax, n_fft=int(sfreq),\n        tmin=cond_2_ival[0], tmax=cond_2_ival[1])\n    ax_2.plot(freqs, np.mean(psds, axis=0))\n\nfig.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define functions for computing activation maps, on which contrast maps are based on.\nContrast maps are spatial maps, computed by subtracting spatial \nalpha power of first condition from spatial alpha power of second condition.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compute_activation_maps(raw, inv):\n\n    tmin, tmax = cond_1_ival[0], cond_1_ival[1]\n    cond_1_psd = mne.minimum_norm.compute_source_psd(\n        raw.copy().crop(tmin+1, tmax-1), inv, method=inv_method, \n        fmin=fmin, fmax=fmax,\n        n_fft=sfreq, pick_ori=None, dB=False)\n    \n    tmin, tmax = cond_2_ival[0], cond_2_ival[1]\n    cond_2_psd = mne.minimum_norm.compute_source_psd(\n        raw.copy().crop(tmin+1, tmax-1), inv, method=inv_method, \n        fmin=fmin, fmax=fmax,\n        n_fft=sfreq, pick_ori=None, dB=False)\n\n    freqs = cond_1_psd.times\n\n    # compute averages over alpha frequency band in the two conditions\n    cond_1_act = np.mean(cond_1_psd._data[:, (freqs >= 7) & (freqs <= 13)], axis=1)\n    cond_2_act = np.mean(cond_2_psd._data[:, (freqs >= 7) & (freqs <= 13)], axis=1)\n\n    vertices = cond_1_psd.vertices\n\n    return cond_1_act, cond_2_act, cond_1_psd, cond_2_psd, freqs, vertices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute contrast maps using the function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "contrast_maps = []\ncond_1_psds = []\ncond_2_psds = []\nfor raw in raws:\n    result = compute_activation_maps(raw, inv)\n    contrast_maps.append(result[1] - result[0])\n    cond_1_psds.append(result[2])\n    cond_2_psds.append(result[3])\n    freqs = result[4]\n    vertices = result[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the PSDs that the contrast maps are based on.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, (ax_1, ax_2) = plt.subplots(2)\nfig.suptitle('PSDs in source space')\nax_1.set_title('Cond 1')\nfor psd in cond_1_psds:\n    ax_1.plot(freqs, np.mean(psd.data, axis=0))\n\nax_2.set_title('Cond 2')\nfor psd in cond_2_psds:\n    ax_2.plot(freqs, np.mean(psd.data, axis=0))\n\nfig.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define function for plotting contrast maps.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_contrast_map(contrast_map, vertices):\n\n    contrast_map = mne.SourceEstimate(contrast_map, vertices, \n                                      tmin=0, tstep=1, subject='sample')\n    brain = contrast_map.plot(\n        'sample', \n        subjects_dir=subjects_dir, \n        hemi='both', alpha=1.0,\n        size=600, title='Contrast map',\n        colorbar=False,\n        time_viewer=False)\n\n    # add centers corresponding to the labels defined earlier\n    brain.add_foci(center_rh_par, coords_as_verts=True, hemi='rh')\n    brain.add_foci(center_lh_par, coords_as_verts=True, hemi='lh')\n    brain.add_foci(center_rh_prec, coords_as_verts=True, hemi='rh')\n    brain.add_foci(center_lh_prec, coords_as_verts=True, hemi='lh')\n    brain.add_foci(center_rh_temp, coords_as_verts=True, hemi='rh')\n    brain.add_foci(center_lh_temp, coords_as_verts=True, hemi='lh')\n\n    brain.show_view(view={'azimuth': 0, 'elevation': 0, 'distance': 550,\n                          'focalpoint': [0, 0, 0]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot average contrast map over all subjects.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_contrast_map(np.mean(contrast_maps, axis=0), vertices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the parietal activation is seen especially in the precentral area, where we \nset up \"constant\" difference. It is not seen in the temporal areas, \nas there the conditions do not differ. It is also not seen in the \nparietal areas, as the differences cancel out there.\nNext, define function for CCA computation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compute_cca(contrast_data, behav_data, n_contrast_components, n_cca_components):\n\n    # rank transform and standardize behav variables\n    behav_data = np.array([scipy.stats.rankdata(elem) for elem in np.array(behav_data).T]).T\n    behav_wh = (behav_data - np.mean(behav_data, axis=0)) / np.std(behav_data, axis=0)\n\n    # rank transform and reduce dimensionality for contrast data\n    contrast_data = np.array([scipy.stats.rankdata(elem) for elem in np.array(contrast_data).T]).T\n    contrast_pca = PCA(\n        n_components=n_contrast_components, whiten=True, random_state=rand_state)\n    contrast_wh = contrast_pca.fit_transform(contrast_data)\n    contrast_mixing = contrast_pca.components_\n\n    # use partial least squares based CCA from Mai et al (2019).\n    cca_contrast_weights, cca_behav_weights = cca_ipls(\n        contrast_wh, behav_wh, \n        alpha_lambda_ratio=penalty_behav_ratio,\n        alpha_lambda=penalty_behav, \n        beta_lambda=penalty_contrast, \n        beta_lambda_ratio=penalty_contrast_ratio,\n        standardize=False,\n        n_pairs=n_cca_components, glm_impl='pyglmnet')\n\n    return cca_contrast_weights, cca_behav_weights, contrast_mixing, contrast_wh, behav_wh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the function to compute the CCA.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cca_contrast_weights, cca_behav_weights, contrast_mixing, contrast_wh, behav_wh = compute_cca(\n    contrast_maps, behavs, n_contrast_components=n_contrast_components, \n    n_cca_components=n_cca_components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define function for plotting canonical weights of behavioral variables.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_behav_weights(comp_idx, cca_behav_weights):\n\n    behav_weights = cca_behav_weights[:, comp_idx]\n\n    fig, ax = plt.subplots()\n    behav_vars = ['Var ' + str(behav_idx+1) for behav_idx in range(len(behav_weights))]\n    ax.bar(behav_vars, behav_weights, align='center', alpha=1.0, width=0.5)\n    ax.axhline(0)\n    ax.set_ylabel('Weight')\n    ax.set_xlabel('Behavioral variable')\n    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define function for plotting canonical weights of contrast variables.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_contrast_weights(comp_idx, cca_contrast_weights, contrast_mixing):\n\n    contrast_weights = np.dot(cca_contrast_weights[:, comp_idx], contrast_mixing)\n    plot_contrast_map(contrast_weights, vertices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define function for scatter plot to visualize canonical correlation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_cca_scatter(comp_idx, contrast_wh, behav_wh, cca_contrast_weights, cca_behav_weights):\n\n    X = np.dot(contrast_wh, cca_contrast_weights[:, comp_idx])\n    Y = np.dot(behav_wh, cca_behav_weights[:, comp_idx])\n\n    fig, ax = plt.subplots()\n    ax.scatter(X, Y, s=100)\n\n    left = np.min(X) - np.max(np.abs(X))*0.1\n    right = np.max(X) + np.max(np.abs(X))*0.1\n\n    a, b = np.polyfit(X, Y, 1)\n    ax.plot(np.linspace(left, right, 2), a*np.linspace(left, right, 2) + b)\n\n    ax.set_xlim(left, right)\n    ax.set_ylim(np.min(Y) - np.max(np.abs(Y))*0.4,\n                np.max(Y) + np.max(np.abs(Y))*0.4)\n\n    ax.set_ylabel('Behavioral correlate')\n    ax.set_xlabel('Brain corralate')\n\n    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the functions defined, plot behav weights.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_behav_weights(0, cca_behav_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot contrast weights.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_contrast_weights(0, cca_contrast_weights, contrast_mixing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot scatter plot.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_cca_scatter(0, contrast_wh, behav_wh, cca_contrast_weights, cca_behav_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define function for running permuted versions of cca.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def permutations(contrast_wh, behav_wh, cca_contrast_weights, cca_behav_weights, n_perm):\n    perm_stats = []\n    for perm_idx, ordering in enumerate([rand_state.permutation(behav_wh.shape[0]) \n                                         for _ in range(n_perm)]):\n\n        # use contrast variables as is is but permutate behav variables\n        contrast_perm = contrast_wh.copy()\n        behav_perm = behav_wh[ordering, :]\n\n        cca_contrast_weights_perm, cca_behav_weights_perm = cca_ipls(\n            contrast_perm, behav_perm, \n            alpha_lambda_ratio=penalty_behav_ratio,\n            alpha_lambda=penalty_behav, \n            beta_lambda=penalty_contrast, \n            beta_lambda_ratio=penalty_contrast_ratio,\n            standardize=False,\n            n_pairs=n_cca_components, glm_impl='pyglmnet')\n\n        # if n_cca_components > 1, use best coef as it might not \n        # always be the first due penalties\n        corrcoefs = []\n        for comp_idx in range(n_cca_components):\n            X = np.dot(contrast_perm, cca_contrast_weights_perm[:, comp_idx])\n            Y = np.dot(behav_perm, cca_behav_weights_perm[:, comp_idx])\n            corrcoefs.append(np.corrcoef(X, Y)[0, 1])\n        perm_stats.append(np.max(corrcoefs))\n\n    # The first canonical correlation using the weights computed previously.\n    X = np.dot(contrast_wh, cca_contrast_weights[:, 0])\n    Y = np.dot(behav_wh, cca_behav_weights[:, 0])\n    sample_stat = np.corrcoef(X, Y)[0, 1]\n\n    # Compute fraction of coefs from permutations that are higher than the\n    # sample coefficient.\n    pvalue = len(list(filter(bool, perm_stats > sample_stat))) / n_perm\n    print(\"Corrcoef for first component: \" + str(round(sample_stat, 4)) + \n          \" (pvalue \" + str(pvalue) + \")\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run permutations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "permutations(contrast_wh, behav_wh, cca_contrast_weights, cca_behav_weights, n_perm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's experiment a bit and try increasing n_subjects to 30.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_subjects = 30\n\nbehav_data = []\nfor idx in range(n_subjects):\n    behav_data.append(rand_state.multivariate_normal(behav_mean, behav_cov))\nbehav_data = np.array(behav_data)\n\ncond_1_deps = np.zeros((n_subjects, 2))\ncond_2_deps = np.array([behav_data[:, 0], np.zeros(n_subjects)]).T\n\nraws, behavs, inv = simulate(n_subjects, cond_1_deps, cond_2_deps)\n\ncontrast_maps = []\nfor raw in raws:\n    result = compute_activation_maps(raw, inv)\n    contrast_maps.append(result[1] - result[0])\n\ncca_contrast_weights, cca_behav_weights, contrast_mixing, contrast_wh, behav_wh = compute_cca(\n    contrast_maps, behavs, n_contrast_components=n_contrast_components, \n    n_cca_components=n_cca_components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the scatter plot.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_cca_scatter(0, contrast_wh, behav_wh, cca_contrast_weights, cca_behav_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the permutation test result.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "permutations(contrast_wh, behav_wh, cca_contrast_weights, cca_behav_weights, n_perm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's next try making the correlation much weaker, from 1.0 to 0.6, \nkeeping the same n_subjects.\nFirst define a function that when given a vector generates another with prespecified correlation to the first one.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def generate_correlated(x, corr):\n    Y = np.random.randn(len(x), 2)\n    C = cholesky([[1, corr], [corr, 1]])\n    Y[:, 0] = x\n    return np.matmul(Y, C)[:, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the function for dependency structure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cond_1_deps = np.zeros((n_subjects, 2))\ncond_2_deps = np.array([generate_correlated(behav_data[:, 0], 0.6), np.zeros(n_subjects)]).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And go on to simulate.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raws, behavs, inv = simulate(n_subjects, cond_1_deps, cond_2_deps)\n\ncontrast_maps = []\nfor raw in raws:\n    result = compute_activation_maps(raw, inv)\n    contrast_maps.append(result[1] - result[0])\n\ncca_contrast_weights, cca_behav_weights, contrast_mixing, contrast_wh, behav_wh = compute_cca(\n    contrast_maps, behavs, n_contrast_components=n_contrast_components, \n    n_cca_components=n_cca_components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the scatter plot.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_cca_scatter(0, contrast_wh, behav_wh, cca_contrast_weights, cca_behav_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the permutation test result.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "permutations(contrast_wh, behav_wh, cca_contrast_weights, cca_behav_weights, n_perm)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}